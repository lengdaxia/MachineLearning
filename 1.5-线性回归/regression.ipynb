{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "#  test\n",
    "import numpy as np\n",
    "\n",
    "np.array([1,2,3])\n",
    "a = np.arange(12).reshape(3,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 误差\n",
    "误差是 $\\varepsilon ^\\left(i\\right)$ 是独立并且具有相同的分布，并服从均值为0，方差为 $\\theta$的高斯分布\n",
    "\n",
    "独立：每个样本之间是独立的，没关系\n",
    "\n",
    "同分布：具有相同的分布\n",
    "\n",
    "高斯分布："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测值与误差：$y^\\left(i\\right) = \\theta^\\left(T\\right)x^\\left(i\\right) + \\varepsilon ^\\left(i\\right)$ .....(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于误差服从高斯分布：$p(\\epsilon^\\left(i\\right)) = \\frac {1}{\\sqrt[]{2\\pi} \\sigma} exp(-\\frac{(\\varepsilon^\\left(i\\right))^2}{2\\sigma^2})$ .....(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将2式代入1式子得：$p(y^\\left(i\\right)| x^\\left(i\\right);\\theta) = \\frac {1}{\\sqrt[]{2\\pi} \\sigma} exp(-\\frac{(y^\\left(i\\right) - \\theta^T x^\\left(i\\right))^2}{2\\sigma^2})$ .....(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 似然函数：$L(\\theta) = \\prod_\\left(i=1\\right)^m p(y^\\left(i\\right)| x^\\left(i\\right);\\theta)  = \\prod_\\left(i=1\\right)^m \\frac {1}{\\sqrt[]{2\\pi} \\sigma} exp(-\\frac{(\\varepsilon^\\left(i\\right))^2}{2\\sigma^2}) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将似然函数转换成对数似然，将累乘变为累加\n",
    "\n",
    "$ J(\\theta) = 1/2 \\sum_\\left(i=1\\right)^m (y^\\left(i\\right) - \\theta^T x^\\left(i\\right))^2 = \\frac {1}{2} (X\\theta - y)^T(X\\theta - y)）$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求偏导数 $ \\nabla_\\theta J(\\theta) = X^TX\\theta - X^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让偏导数等于0 : $\\theta = (X^TX)^\\left(-1\\right) X^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估方法\n",
    "\n",
    " 最常用的评估项 $ R^2:1- \\frac {\\sum_\\left(i=1\\right)^m (y_i^\\hat - y_i)^2}{\\sum_\\left(i=1\\right)^m (y_i - \\overline y)^2}$\n",
    "\n",
    "R 取值越等于1，我们认为模型拟合越小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降\n",
    "\n",
    "引入：当我们得到一个目标函数后，如何进行求解？\n",
    "\n",
    "常规套路：机器学习的套路就是我交给机器一堆数据，然后告诉它什么样的学习方式是对的（目标函数），然后让他朝着这个方向去做\n",
    "\n",
    "如何优化：一步步迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 批量梯度下降：容易得到最优解，但是由于每次考虑所以样本，速度很慢\n",
    "\n",
    "- 随机梯度下降：每次找一个样本，迭代速度快，但不一定每次都朝着收敛的方向\n",
    "\n",
    "- 小批量梯度下降法：每次更新选择一小部分数据来算，实用！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习率（步长）\n",
    "- 对结果会产生巨大的影响，一般小一点 （0.01-更小）\n",
    "- 如何选择：从小的\n",
    "- 批处理数量：32，64，128... 综合考虑内存和效率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 逻辑回归 （Logistics Regression）\n",
    "- 经典的二分类的算法\n",
    "- 机器学习算法选择，先逻辑回归再用复杂的，能简单的再用简单的\n",
    "- 逻辑回归的决策边界，可以是非线性的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmod 函数\n",
    "- 公式： $g(Z) = \\frac {1}{1+e^\\left(-z\\right)}$\n",
    "- 自变量取值为任意实数，值域 [0,1]\n",
    "- 解释:将任意的输入映射到[0,1]区间，我们在线性回归中可以得到一个预测值，再将该值映射到Sigmond函数，这样就完成了从值到概率的转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
